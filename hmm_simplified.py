# -*- coding: utf-8 -*-
"""HMM simplified

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12yf9ar7JAfIzLAkKEihqrdEOPLfu4C92
"""

from scipy.io import arff
import pandas as pd
import numpy as np
from scipy.signal import butter, filtfilt
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive', force_remount=True)

import numpy as np
import matplotlib.pyplot as plt

def plot_labels(labels, epoch_duration, title):

  epoch_duration_frames = 1/(128*epoch_duration)  # in seconds (change this if using 0.5s or 2s epochs)

  n_labels = len(labels)
  time_axis = np.arange(n_labels) * epoch_duration

  labels_2d = labels.reshape(1, -1)

  plt.figure(figsize=(12, 1.5))
  plt.imshow(labels_2d, aspect='auto', cmap='coolwarm', interpolation='nearest', extent=[0, n_labels * epoch_duration_frames, 0, 1])



  plt.yticks([])  # Hide y-axis (only one row)
  tick_interval = 5  # seconds between x-ticks
  xticks = np.arange(0, n_labels * epoch_duration_frames + 1, tick_interval)
  plt.xticks(xticks)
  plt.xlabel('Time')
  plt.title(f'{title}')
  plt.colorbar(label='Eye State')
  plt.tight_layout()
  plt.show()

# Load dataset
file_path = '/content/drive/MyDrive/Final_Project_Stats/EEG_Eye_State.arff'
data, meta = arff.loadarff(file_path)
df = pd.DataFrame(data)
data = df.to_numpy()  # Shape: (14930, 15)

# Extract labels and data
labels = data[:, 14]
decoded_labels = np.array([x.decode('utf-8') for x in labels]).astype(int)
data = np.delete(data, 14, 1).astype(np.float32)  # Shape: (14930, 14)
sampling_rate = round(14930 / 117)  # ~128 Hz

# Outlier removal
mask = np.ones(len(data), dtype=bool)
for i in range(14):
    Q1 = np.percentile(data[:, i], 25)
    Q3 = np.percentile(data[:, i], 75)
    IQR = Q3 - Q1
    outlier_mask = (data[:, i] < (Q1 - 10 * IQR)) | (data[:, i] > (Q3 + 5 * IQR))
    mask = ~outlier_mask & mask
filtered_data = data[mask]
decoded_labels = decoded_labels[mask]

# Common average referencing
average = filtered_data.mean(axis=1, keepdims=True)
average_data = filtered_data - average

# Bandpass filter
def bandpass_filter(data, lowcut, highcut, fs, order=4):
    nyq = 0.5 * fs
    low = lowcut / nyq
    high = highcut / nyq
    b, a = butter(order, [low, high], btype='band')
    filtered_data = filtfilt(b, a, data, axis=0)
    return filtered_data

bandpass_filtered_data = bandpass_filter(average_data, 1, 40, sampling_rate)

# Split into 115 1-second epochs
epoch_labels = np.array([])
epoch_data = []
for i in range(115):
    labels_subset = decoded_labels[i*128 : (i+1)*128]
    epoch_labels = np.append(epoch_labels, round(np.mean(labels_subset)))
    data_subset = bandpass_filtered_data[i*128 : (i+1)*128, :]
    epoch_data.append(data_subset)
epoch_data = np.array(epoch_data)  # Shape: (115, 128, 14)
epoch_labels = np.array(epoch_labels, dtype=np.int64)  # Shape: (115,)

# Normalize data within each epoch
for i in range(epoch_data.shape[0]):
    std = np.std(epoch_data[i, :, :])
    mean = np.mean(epoch_data[i, :, :])
    epoch_data[i, :, :] = (epoch_data[i, :, :] - mean) / std

# Merge consecutive 1-second epochs into 2-second epochs
merged_epochs = []
merged_labels = []
for i in range(0, epoch_data.shape[0] - 1, 2):
    if epoch_labels[i] == epoch_labels[i+1]:
        merged = np.vstack([epoch_data[i], epoch_data[i+1]])  # (256, 14)
        merged_epochs.append(merged)
        merged_labels.append(epoch_labels[i])
epoch_data_256 = np.stack(merged_epochs, axis=0)  # Shape: (N2, 256, 14)
epoch_labels_256 = np.array(merged_labels, dtype=np.int64)  # Shape: (N2,)

!pip install hmmlearn
from sklearn.model_selection import StratifiedKFold
from hmmlearn import hmm
from scipy.stats import mode
from sklearn.metrics import accuracy_score
import numpy as np

predicted_labels = []
true_labels = []

# 10-Fold Cross-Validation for Gaussian HMM
def run_10fold_cv_gaussian_hmm(X, y, seq_len=128, n_feats=14, n_splits=10, random_state=0):
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)
    accuracies = []
    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), 1):
        X_train_seq = X[train_idx]
        X_test_seq = X[test_idx]
        y_train_seq = y[train_idx]
        y_test_seq = y[test_idx]
        X_train_flat = X_train_seq.reshape(-1, n_feats)
        X_test_flat = X_test_seq.reshape(-1, n_feats)
        train_lengths = [seq_len] * len(X_train_seq)
        test_lengths = [seq_len] * len(X_test_seq)
        ghmm = hmm.GaussianHMM(
            n_components=2,
            covariance_type='diag',
            n_iter=200,
            random_state=random_state
        ).fit(X_train_flat, train_lengths)
        hidden_test = ghmm.predict(X_test_flat, test_lengths)
        hidden_epoch = mode(hidden_test.reshape(-1, seq_len), axis=1).mode.ravel()
        state_to_label = {}
        for s in range(ghmm.n_components):
            mask = hidden_epoch == s
            if mask.sum() == 0:
                state_to_label[s] = 0
                continue
            majority = np.round(y_test_seq[mask].mean()).astype(int)
            state_to_label[s] = majority
        mapped_pred = np.vectorize(state_to_label.get)(hidden_epoch)
        fold_accuracy = accuracy_score(y_test_seq.ravel(), mapped_pred)

        predicted_labels.append(mapped_pred)
        true_labels.append(y_test_seq.ravel())

        print(f'Fold {fold} - Gaussian HMM Accuracy: {fold_accuracy:.3f}')
        accuracies.append(fold_accuracy)
    mean_acc = np.mean(accuracies)
    std_acc = np.std(accuracies)
    print(f"\n=== 10-Fold Cross-Validation Results (Gaussian HMM, 1s epochs) ===")
    print(f"Mean Accuracy: {mean_acc:.3f} Â± {std_acc:.3f} (over {n_splits} folds)")
    return mean_acc, std_acc

# Run 10-fold cross-validation
mean_acc_gaussian, std_acc_gaussian = run_10fold_cv_gaussian_hmm(epoch_data, epoch_labels, seq_len=128, n_feats=14)

print(len(true_labels))
print(len(predicted_labels))
pred_labels0 = predicted_labels[0]
true_labels0 = true_labels[0]

plot_labels(true_labels0, 2, 'True Labels')
plot_labels(pred_labels0, 2, 'Unsupervised HMM Predicted Labels')

import torch
import numpy as np
from torch.distributions import MultivariateNormal
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, confusion_matrix

# Hyperparameters
SEQ_LEN = 128
K = 2
N_SPLITS = 10
JITTER = 1e-2

predicted_labels = []
true_labels = []

# Viterbi decoding function
def viterbi_decode_epoch(epoch_tensor, log_startprob, log_transprob, emissions):
    T = epoch_tensor.shape[0]
    dp = torch.full((T, K), float('-inf'))
    backp = torch.zeros((T, K), dtype=torch.long)
    for s in range(K):
        dp[0, s] = log_startprob[s] + emissions[s].log_prob(epoch_tensor[0])
        backp[0, s] = -1
    for t in range(1, T):
        x_t = epoch_tensor[t]
        for s in range(K):
            emission_lp = emissions[s].log_prob(x_t)
            prev_vals = dp[t-1, :] + log_transprob[:, s]
            best_prev = torch.argmax(prev_vals)
            dp[t, s] = prev_vals[best_prev] + emission_lp
            backp[t, s] = best_prev
    best_path = torch.zeros(T, dtype=torch.long)
    best_path[T-1] = torch.argmax(dp[T-1, :])
    for t in range(T-2, -1, -1):
        best_path[t] = backp[t+1, best_path[t+1]]
    return best_path

# 10-Fold Cross-Validation for Supervised HMM
def run_10fold_cv_supervised_hmm_1s(X, y, seq_len=128, n_splits=10, random_state=0):
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)
    accuracies = []
    X_t = torch.from_numpy(X.astype(np.float32))
    y_t = torch.from_numpy(y.astype(np.int64))
    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), 1):
        X_train_epochs = X_t[train_idx]
        y_train_epochs = y_t[train_idx]
        X_test_epochs = X_t[test_idx]
        y_test_epochs = y_t[test_idx]
        X_train_flat = X_train_epochs.reshape(-1, 14)
        y_train_flat = y_train_epochs.repeat_interleave(seq_len)
        means = []
        covs = []
        for s in range(K):
            mask_s = (y_train_flat == s)
            xs = X_train_flat[mask_s]
            if xs.shape[0] < 2:
                other = 1 - s
                ref_xs = X_train_flat[y_train_flat == other]
                mu = ref_xs.mean(dim=0)
                cov_np = torch.cov(ref_xs.T).numpy()
                cov_mat = torch.from_numpy(cov_np) + (JITTER * torch.eye(14))
            else:
                mu = xs.mean(dim=0)
                cov_np = torch.cov(xs.T).numpy()
                cov_mat = torch.from_numpy(cov_np) + (JITTER * torch.eye(14))
            means.append(mu)
            covs.append(cov_mat)
        means = torch.stack(means, dim=0)
        covs = torch.stack(covs, dim=0)
        trans_counts = torch.zeros((K, K))
        for lbl in y_train_epochs:
            trans_counts[lbl, lbl] += seq_len - 1
        trans_probs = (trans_counts + 1.0) / (trans_counts + 1.0).sum(dim=1, keepdim=True)
        log_startprob = torch.log(torch.tensor([0.5, 0.5]))
        log_transprob = torch.log(trans_probs)
        emissions = [MultivariateNormal(loc=means[s], covariance_matrix=covs[s]) for s in range(K)]
        hidden_epoch_preds = []
        for e in range(X_test_epochs.shape[0]):
            epoch_tensor = X_test_epochs[e]
            path = viterbi_decode_epoch(epoch_tensor, log_startprob, log_transprob, emissions)
            pred_label = torch.mode(path).values.item()
            hidden_epoch_preds.append(pred_label)

        predicted_labels.append(hidden_epoch_preds)
        true_labels.append(y_test_epochs)

        hidden_epoch_preds = torch.tensor(hidden_epoch_preds)
        fold_accuracy = accuracy_score(y_test_epochs.numpy(), hidden_epoch_preds.numpy())
        print(f'Fold {fold} - Supervised HMM (1s) Accuracy: {fold_accuracy:.3f}')
        accuracies.append(fold_accuracy)
    mean_acc = np.mean(accuracies)
    std_acc = np.std(accuracies)
    print(f"\n=== 10-Fold Cross-Validation Results (Supervised HMM, 1s epochs) ===")
    print(f"Mean Accuracy: {mean_acc:.3f} Â± {std_acc:.3f} (over {n_splits} folds)")
    return mean_acc, std_acc

# Run 10-fold cross-validation
mean_acc_supervised_1s, std_acc_supervised_1s = run_10fold_cv_supervised_hmm_1s(epoch_data, epoch_labels, seq_len=128)

import torch
import numpy as np
from torch.distributions import MultivariateNormal
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, confusion_matrix

# Hyperparameters
SEQ_LEN = 256
K = 2
N_SPLITS = 10
JITTER = 1e-2

predicted_labels = []
true_labels = []

# Viterbi decoding function
def viterbi_decode_epoch(epoch_tensor, log_startprob, log_transprob, emissions):
    T = epoch_tensor.shape[0]
    dp = torch.full((T, K), float('-inf'))
    backp = torch.zeros((T, K), dtype=torch.long)
    for s in range(K):
        dp[0, s] = log_startprob[s] + emissions[s].log_prob(epoch_tensor[0])
        backp[0, s] = -1
    for t in range(1, T):
        x_t = epoch_tensor[t]
        for s in range(K):
            emission_lp = emissions[s].log_prob(x_t)
            prev_vals = dp[t-1, :] + log_transprob[:, s]
            best_prev = torch.argmax(prev_vals)
            dp[t, s] = prev_vals[best_prev] + emission_lp
            backp[t, s] = best_prev
    best_path = torch.zeros(T, dtype=torch.long)
    best_path[T-1] = torch.argmax(dp[T-1, :])
    for t in range(T-2, -1, -1):
        best_path[t] = backp[t+1, best_path[t+1]]
    return best_path

# 10-Fold Cross-Validation
def run_10fold_cv_supervised_hmm_2s(X, y, seq_len=256, n_splits=10, random_state=0):
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)
    accuracies = []
    X_t = torch.from_numpy(X.astype(np.float32))
    y_t = torch.from_numpy(y.astype(np.int64))
    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), 1):
        X_train_epochs = X_t[train_idx]
        y_train_epochs = y_t[train_idx]
        X_test_epochs = X_t[test_idx]
        y_test_epochs = y_t[test_idx]
        X_train_flat = X_train_epochs.reshape(-1, 14)
        y_train_flat = y_train_epochs.repeat_interleave(seq_len)
        means = []
        covs = []
        for s in range(K):
            mask_s = (y_train_flat == s)
            xs = X_train_flat[mask_s]
            if xs.shape[0] < 2:
                other = 1 - s
                ref_xs = X_train_flat[y_train_flat == other]
                mu = ref_xs.mean(dim=0)
                cov_np = torch.cov(ref_xs.T).numpy()
                cov_mat = torch.from_numpy(cov_np) + (JITTER * torch.eye(14))
            else:
                mu = xs.mean(dim=0)
                cov_np = torch.cov(xs.T).numpy()
                cov_mat = torch.from_numpy(cov_np) + (JITTER * torch.eye(14))
            means.append(mu)
            covs.append(cov_mat)
        means = torch.stack(means, dim=0)
        covs = torch.stack(covs, dim=0)
        trans_counts = torch.zeros((K, K))
        for lbl in y_train_epochs:
            trans_counts[lbl, lbl] += seq_len - 1
        trans_probs = (trans_counts + 1.0) / (trans_counts + 1.0).sum(dim=1, keepdim=True)
        log_startprob = torch.log(torch.tensor([0.5, 0.5]))
        log_transprob = torch.log(trans_probs)
        emissions = [MultivariateNormal(loc=means[s], covariance_matrix=covs[s]) for s in range(K)]
        hidden_epoch_preds = []
        for e in range(X_test_epochs.shape[0]):
            epoch_tensor = X_test_epochs[e]
            path = viterbi_decode_epoch(epoch_tensor, log_startprob, log_transprob, emissions)
            pred_label = torch.mode(path).values.item()
            hidden_epoch_preds.append(pred_label)
        hidden_epoch_preds = torch.tensor(hidden_epoch_preds)
        fold_accuracy = accuracy_score(y_test_epochs.numpy(), hidden_epoch_preds.numpy())
        print(f'Fold {fold} - Supervised HMM (2s) Accuracy: {fold_accuracy:.3f}')
        accuracies.append(fold_accuracy)
    mean_acc = np.mean(accuracies)
    std_acc = np.std(accuracies)
    print(f"\n=== 10-Fold Cross-Validation Results (Supervised HMM, 2s epochs) ===")
    print(f"Mean Accuracy: {mean_acc:.3f} Â± {std_acc:.3f} (over {n_splits} folds)")
    return mean_acc, std_acc

# Run 10-fold cross-validation
mean_acc_supervised_2s, std_acc_supervised_2s = run_10fold_cv_supervised_hmm_2s(epoch_data_256, epoch_labels_256, seq_len=256)

print(len(true_labels))
print(len(predicted_labels))
pred_labels4 = predicted_labels[0]
pred_labels4 = np.array(pred_labels4)
true_labels4 = true_labels[0]

plot_labels(true_labels4, 2, 'True Labels')
plot_labels(pred_labels4, 2, 'Supervised HMM Predicted Labels')