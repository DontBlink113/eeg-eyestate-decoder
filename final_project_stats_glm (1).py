# -*- coding: utf-8 -*-
"""Final Project Stats GLM

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16k-i_Nl7eAbwWkcabk2DxvAFUfLqtfWz
"""

from google.colab import drive
drive.mount('/content/drive')
sampling_rate = 128


#Dataset: https://archive.ics.uci.edu/dataset/264/eeg+eye+state

from google.colab import drive
import numpy as np
import pandas as pd
from scipy.io import arff
from scipy.signal import butter, filtfilt


class EEGPreprocessor:
    """Handles EEG data preprocessing (filtering, referencing, outlier removal, epoching)."""
    def __init__(self, sampling_rate, lowcut=1, highcut=40):
        self.sampling_rate = sampling_rate
        self.lowcut = lowcut
        self.highcut = highcut

    def load_data(self, file_path):
        """Load ARFF file and extract data and labels."""
        data, meta = arff.loadarff(file_path)
        df = pd.DataFrame(data)
        raw_data = df.iloc[:, :-1].to_numpy().astype(np.float32)  # Shape (14980, 14)
        labels = np.array([x.decode('utf-8') for x in df.iloc[:, -1]]).astype(int)
        return raw_data, labels

    def remove_outliers(self, data, labels, min_voltage=1000, max_voltage=10000):
        """Remove rows with extreme voltage values."""
        bad_mask = np.any((data < min_voltage) | (data > max_voltage), axis=1)
        bad_indices = np.where(bad_mask)[0]
        print(f"Number of rows removed: {len(bad_indices)}")
        return np.delete(data, bad_indices, axis=0), np.delete(labels, bad_indices)

    def apply_car(self, data):
        """Apply common average referencing."""
        average = data.mean(axis=1, keepdims=True)
        return data - average

    def bandpass_filter(self, data):
        """Apply zero-phase bandpass filter."""
        nyq = 0.5 * self.sampling_rate
        low = self.lowcut / nyq
        high = self.highcut / nyq
        b, a = butter(4, [low, high], btype='band')
        return filtfilt(b, a, data, axis=0)

'''
PREPROCESSING

1) Removing extremely high/low voltage measurements
2) Rereferencing Data (Common Average Referencing)
3) Apply a Bandpass filter (1hz to 40hz) to isolate important frequencies
4) Sort the labels into epochs (for each model that we use. Each model's individual preprocessing starts here)
'''


eeg_processor = EEGPreprocessor(sampling_rate=128)
raw_data, raw_labels = eeg_processor.load_data('/content/drive/MyDrive/Final_Project_Stats/EEG_Eye_State.arff')
no_outliers, labels_no_outliers = eeg_processor.remove_outliers(raw_data, raw_labels)
data_car = eeg_processor.apply_car(no_outliers)
bandpass_data = eeg_processor.bandpass_filter(data_car)

labels = labels_no_outliers

import numpy as np
import pandas as pd

def get_stats_by_eye_state_np(data, labels, channel_names=None):
    """
    Compute min, max, and mean for each channel, split by eye state.
    Returns a dict of DataFrames: { 'open': df, 'closed': df }
    """
    if channel_names is None:
        channel_names = [f'ch{i}' for i in range(data.shape[1])]

    stats = {}
    for state, label in [('open', 0), ('closed', 1)]:
        subset = data[labels == label]
        mins = subset.min(axis=0)
        maxs = subset.max(axis=0)
        means = subset.mean(axis=0)

        matrix = np.stack([mins, maxs, means], axis=1)  # (num_channels, 3)
        stats[state] = pd.DataFrame(matrix, index=channel_names, columns=['min', 'max', 'mean'])
    return stats

def print_stats_table(df, title):
    print(f"\n{title}")
    # Set consistent column widths
    print("{:<6} {:>12} {:>12} {:>12}".format("Chan", "Min", "Max", "Mean"))
    for idx, row in df.iterrows():
        print("{:<6} {:>12.2f} {:>12.2f} {:>12.2f}".format(
            idx, row['min'], row['max'], row['mean']
        ))

def get_stats_by_eye_state(data, labels, channel_names=None):
  df = get_stats_by_eye_state_np(data, labels )
  print_stats_table(df['open'], "Open Eye State")
  print_stats_table(df['closed'], "Closed Eye State")

get_stats_by_eye_state(raw_data, labels_raw)

#Plot the EEG Data
import matplotlib.pyplot as plt

def plot_eeg_signal(eeg_data, channel, sampling_rate, start, end):

  plt.figure(figsize=(10, 6))
  plt.plot(eeg_data[(start * 117) : (end*117), channel], label=f'Channel {channel}')

  plt.xlabel('instances)')
  plt.title('EEG Signal Channel 1)')
  plt.legend()
  plt.grid(True)
  plt.tight_layout()
  plt.show()


plot_eeg_signal(bandpass_data, 3, sampling_rate, 0, 15)

import numpy as np
import matplotlib.pyplot as plt

def plot_labels(labels, epoch_duration, title):

  epoch_duration_frames = 1/(128*epoch_duration)  # in seconds (change this if using 0.5s or 2s epochs)

  n_labels = len(labels)
  time_axis = np.arange(n_labels) * epoch_duration

  labels_2d = labels.reshape(1, -1)

  plt.figure(figsize=(12, 1.5))
  plt.imshow(labels_2d, aspect='auto', cmap='coolwarm', interpolation='nearest', extent=[0, n_labels * epoch_duration_frames, 0, 1])



  plt.yticks([])  # Hide y-axis (only one row)
  tick_interval = 5  # seconds between x-ticks
  xticks = np.arange(0, n_labels * epoch_duration_frames + 1, tick_interval)
  plt.xticks(xticks)
  plt.xlabel('Time (seconds)')
  plt.title(f'{title}')
  plt.colorbar(label='Eye State')
  plt.tight_layout()
  plt.show()

plot_labels(labels_no_outliers, 1, "Actual Labels Whole dataset")

import numpy as np
import torch
from scipy.signal import welch
from sklearn.model_selection import train_test_split

class EEGFeatureExtractor:
    """Extracts and prepares features from preprocessed EEG data for classification."""

    def __init__(self, sampling_rate, epoch_duration=1.0, test_size=0.2):
        """
        Initialize the feature extractor.

        Args:
            sampling_rate (int): Sampling rate of the EEG data (Hz).
            epoch_duration (float): Duration of each epoch in seconds (default: 1.0).
            test_size (float): Proportion of data for testing (default: 0.2).
        """
        self.sampling_rate = sampling_rate
        self.epoch_duration = epoch_duration
        self.test_size = test_size

    def create_epochs(self, data, labels):
        """Segment data into epochs and assign labels."""
        samples_per_epoch = int(self.sampling_rate * self.epoch_duration)
        n_epochs = data.shape[0] // samples_per_epoch
        epoch_data = []
        epoch_labels = []
        for i in range(n_epochs):
            start = i * samples_per_epoch
            end = start + samples_per_epoch
            epoch_data.append(data[start:end, :])
            epoch_labels.append(round(np.mean(labels[start:end])))
        return np.array(epoch_data), np.array(epoch_labels).astype(int)

    def normalize_epochs(self, epoch_data):
        """Normalize each epoch to zero mean and unit variance."""
        for i in range(epoch_data.shape[0]):
            mean = np.mean(epoch_data[i, :, :])
            std = np.std(epoch_data[i, :, :])
            epoch_data[i, :, :] = (epoch_data[i, :, :] - mean) / (std + 1e-8)
        return epoch_data

    def compute_psd_features(self, epoch_data):
        """Compute power spectral density features for each epoch."""
        all_psd = []
        for epoch in epoch_data:
            f, psd = welch(epoch, fs=self.sampling_rate, axis=0)
            psd = psd[:40, :]  # Keep frequencies up to 40 Hz
            all_psd.append(psd)
        return np.array(all_psd), f[:40]

    def flatten_data(self, data):
        return data.reshape(data.shape[0], -1)


    def split_data(self, data, labels):

        # Train-test split
        X_train, X_test, y_train, y_test = train_test_split(
            data, labels, test_size=self.test_size
        )
        # Convert to torch tensors and ensure float32
        X_train = torch.tensor(np.abs(X_train).astype(np.float32))
        X_test = torch.tensor(np.abs(X_test).astype(np.float32))
        y_train = torch.tensor(np.abs(y_train).astype(np.float32))
        y_test = torch.tensor(np.abs(y_test).astype(np.float32))


        return X_train, X_test, y_train, y_test

import torch
import numpy as np

class LinearRegression:
    """Logistic Regression model for binary classification of EEG data."""

    def __init__(self, input_dim, learning_rate=0.2, n_iterations=1000):
        """
        Initialize the logistic regression model.

        Args:
            input_dim (int): Number of input features.
            learning_rate (float): Learning rate for gradient ascent.
            n_iterations (int): Number of training iterations.
        """
        self.input_dim = input_dim
        self.learning_rate = learning_rate
        self.n_iterations = n_iterations

        self.weights = torch.nn.Parameter(torch.rand(input_dim))
        self.bias = torch.nn.Parameter(torch.rand(1))
        self.optimizer = torch.optim.SGD([self.weights, self.bias], lr=self.learning_rate)


    def link_function(self, data):
        """Apply sigmoid link function for logistic regression."""
        z = torch.matmul(data, self.weights) + self.bias
        return torch.sigmoid(z)

    def log_likelihood(self, data, labels):
        """Compute log-likelihood for the model."""
        preds = self.link_function(data)
        eps = 1e-8  # Prevent log(0)
        return torch.sum(labels * torch.log(preds + eps) + (1 - labels) * torch.log(1 - preds + eps))

    def predict(self, data):
        """Predict binary class labels (0 or 1)."""
        probs = self.link_function(data)
        return (probs > 0.5).float()

    def update_weights(self, data, labels):
        self.optimizer.zero_grad()
        loss = -self.log_likelihood(data, labels)  # Negative log-likelihood (minimize it)
        loss.backward()
        self.optimizer.step()


    def train(self, X_train, y_train):
        """Train the logistic regression model."""
        print("Starting training...")
        for i in range(self.n_iterations):
            self.update_weights(X_train, y_train)
            ll = self.log_likelihood(X_train, y_train)
            if (i + 1) % 100 == 0:  # Print every 100 iterations
                print(f"Iteration {i + 1}, Log-Likelihood: {ll.item():.4f}")
        print("Training complete.")

    def evaluate(self, X_test, y_test):
        """Evaluate the model on test data."""
        predictions = self.predict(X_test)
        accuracy = torch.mean((predictions == y_test).float())
        print(f"Test Accuracy: {accuracy.item():.4f}")
        return accuracy.item()

    def get_parameters(self):
        """Return model parameters."""
        return self.weights.detach().numpy(), self.bias.detach().numpy()

#Dream Dataset, ignore this

import numpy as np
import torch
from sklearn.model_selection import train_test_split

# Parameters
n_samples = 1000  # Total samples
n_features = 5     # Number of features
noise_std = 10   # Minimal noise standard deviation

# Generate labels (balanced: 5000 zeros, 5000 ones)
labels = np.concatenate([np.zeros(n_samples // 2), np.ones(n_samples // 2)], axis=0)

# Generate features: linear relationship with label + noise
data = np.zeros((n_samples, n_features))
for i in range(n_features):
    # Each feature is 10 * label + small noise
    data[:, i] = 10 * labels + np.random.normal(0, noise_std, n_samples)

# Convert to torch tensors
X = torch.tensor(data, dtype=torch.float32)
y = torch.tensor(labels, dtype=torch.float32)

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

print(f"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}")
print(f"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}")

# Optional: Print first few samples to verify
print("\nFirst 5 samples (features) and labels:")
for i in range(5):
    print(f"Sample {i}: {X[i].numpy()}, Label: {y[i].item()}")

def linear_regression_pipeline():
    # Constants
    SAMPLING_RATE = 128
    EPOCH_DURATION = 0.5
    FILE_PATH = '/content/drive/MyDrive/Final_Project_Stats/EEG_Eye_State.arff'

    # Preprocessing
    eeg_processor = EEGPreprocessor(sampling_rate=SAMPLING_RATE)
    raw_data, labels = eeg_processor.load_data(FILE_PATH)
    no_outliers, labels_no_outliers = eeg_processor.remove_outliers(raw_data, labels, min_voltage=1000, max_voltage=10000)
    data_car = eeg_processor.apply_car(no_outliers)
    filtered_data = eeg_processor.bandpass_filter(data_car)
    # bandpass_data = eeg_processor.bandpass_filter(no_outliers)

    feature_extractor = EEGFeatureExtractor(sampling_rate=128, epoch_duration=0.5)
    epoch_data, epoch_labels = feature_extractor.create_epochs(filtered_data, labels_no_outliers)
    normalized_epoch_data = feature_extractor.normalize_epochs(epoch_data)
    all_psd, f = feature_extractor.compute_psd_features(normalized_epoch_data)
    all_psd = all_psd[:, :20, :]
    f = f[:20]

    print(f"PSD shape: {all_psd.shape}, Labels shape: {epoch_labels.shape}")

    all_psd = feature_extractor.flatten_data(all_psd)

    X_train, X_test, y_train, y_test = feature_extractor.split_data(all_psd, epoch_labels)
    print(f"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}")
    print(f"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}")

    # Logistic Regression
    lr_model = LinearRegression(input_dim=X_train.shape[1], learning_rate = 0.1)
    lr_model.train(X_train, y_train)
    accuracy = lr_model.evaluate(X_test, y_test)
    predictions = lr_model.predict(X_test)
    print("\nTest Set Predictions vs True Labels:")
    weights, bias = lr_model.get_parameters()
    print(f"Weights shape: {weights.shape}, Bias: {bias}")
    return accuracy, predictions, y_test

total_accuracy = 0
for i in range(10):
  accuracy, predictions, y_test = linear_regression_pipeline()
  total_accuracy += accuracy
  if (accuracy > 0.5):
    y_predictions_official = predictions.numpy()
    y_test_official = y_test.numpy()
print("average accuracy:", total_accuracy/10)

plot_labels(y_test_official, 0.5, "True labels")
plot_labels(y_predictions_official, 0.5, "GLM Predicted Labels")